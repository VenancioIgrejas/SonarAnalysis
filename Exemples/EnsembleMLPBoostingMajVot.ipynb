{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple using MLP multi-class with boosting and majority vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Dataset Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading Data] done in 0.00217604637146\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print('[{0}] done in {1}'.format(name,time.time() - t0))\n",
    "    \n",
    "\n",
    "with timer('Loading Data'):\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform dataset in dataframe\n",
    "\n",
    "df_data = pd.DataFrame(data=X,columns=iris.feature_names)\n",
    "df_trgt = pd.DataFrame(data=y,columns=['target'])\n",
    "df = pd.concat([df_data,df_trgt],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "from Functions.mlpClassification import MLPSKlearn\n",
    "from Functions.ensemble import AdaBoost\n",
    "#from hep_ml.nnet import MLPClassifier\n",
    "from hep_ml.nnet import MLPMultiClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import AdaBoostClassifier,VotingClassifier\n",
    "\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(40,),\n",
    "#                    activation='tanh',\n",
    "#                    solver='adam',\n",
    "#                    alpha=0.0001, \n",
    "#                    batch_size='auto',\n",
    "#                    learning_rate='constant',\n",
    "#                    learning_rate_init=0.001,\n",
    "#                    power_t=0.5,\n",
    "#                    max_iter=1000,\n",
    "#                    shuffle=True,\n",
    "#                    random_state=None,\n",
    "#                    tol=0.01,\n",
    "#                    verbose=True,\n",
    "#                    warm_start=False,\n",
    "#                    momentum=0.9,\n",
    "#                    nesterovs_momentum=True,\n",
    "#                    early_stopping=True,\n",
    "#                    validation_fraction=0.2,\n",
    "#                    beta_1=0.9,\n",
    "#                    beta_2=0.999,\n",
    "#                    epsilon=1e-08)\n",
    "\n",
    "#neural = MLPClassifier(layers=[10], trainer='adadelta', trainer_parameters={'batch': 600})\n",
    "#mlp = MLPMultiClassifier(layers=(10,), scaler='standard', trainer='irprop-', epochs=100,\n",
    "#                trainer_parameters=None, random_state=None)\n",
    "\n",
    "mlp = MLPSKlearn()\n",
    "#mlp = MLPhep()\n",
    "\n",
    "estimator = 20\n",
    "boost = AdaBoost(base_estimator=mlp,\n",
    "                 n_estimators=estimator,\n",
    "                 algorithm='SAMME.R')\n",
    "#mlp = MLPClassifier()\n",
    "#mj_vot = VotingClassifier(tuple(classifier.estimators_),n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n",
      "[+] 1 of 1 inits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoost(algorithm='SAMME.R',\n",
       "     base_estimator=MLPSKlearn(activation=None, alpha=None, batch_size=None, beta_1=None,\n",
       "      beta_2=None, dir=None, early_stopping=None, epsilon=None,\n",
       "      hidden_layer_sizes=None, learning_rate=None, learning_rate_init=None,\n",
       "      max_iter=None, momentum=None, n_iter_no_change=None,\n",
       "      nesterovs_momentum=None, power_t=None, shuffle=None, solver=None,\n",
       "      tol=None, validation_fraction=None, verbose=None, warm_start=None),\n",
       "     learning_rate=1.0, n_estimators=20, random_state=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usingo only MLP simple \n",
    "#mlp.fit(data_preproc_train,y_train)\n",
    "\n",
    "#using MLP with boosting\n",
    "boost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venancio/sonarteste/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "boost.set_classes(y_test)\n",
    "output = boost.predic_maj(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         8\n",
      "          1       0.27      0.43      0.33         7\n",
      "          2       0.79      1.00      0.88        15\n",
      "\n",
      "avg / total       0.46      0.60      0.52        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print classification_report(y_pred=output,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = (100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'teste':'teste'}\n",
    "dic1 = {'teste1':'teste1','poxa':'poxa'}\n",
    "dic2 = {'teste2':'teste2'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dic = dic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dic.update(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dic.update(dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poxa': 'poxa', 'teste': 'teste', 'teste1': 'teste1', 'teste2': 'teste2'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
