{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from classificationConfig import CONFIG\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from NeuralNetworkAnalysis import NeuralNetworkAnalysis as nna\n",
    "\n",
    "from Functions.MetricCustom import ind_SP\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "analysis_name = 'Classification'\n",
    "\n",
    "data_path = CONFIG['OUTPUTDATAPATH']\n",
    "results_path = CONFIG['PACKAGE_NAME']\n",
    "class_interest = [1,2,3,4]#[6,7,9,16,21,23]\n",
    "\n",
    "nums_componets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Time to read data file: 2.90071892738 seconds\n",
      "analysis of Class01: \n",
      "size: 3209x400 -- maxValue: 1.38463282277 -- minValue: -0.199999448771\n",
      "analysis of Class02: \n",
      "size: 3037x400 -- maxValue: 1.34259549045 -- minValue: -0.199998892824\n",
      "analysis of Class03: \n",
      "size: 3212x400 -- maxValue: 1.49508318988 -- minValue: -0.199998792195\n",
      "analysis of Class04: \n",
      "size: 3203x400 -- maxValue: 1.38544304863 -- minValue: -0.199999766141\n",
      "analysis of Class05: \n",
      "size: 4781x400 -- maxValue: 2.08462558961 -- minValue: -0.199999495607\n",
      "analysis of Class06: \n",
      "size: 2232x400 -- maxValue: 1.03378591259 -- minValue: -0.199999021577\n",
      "analysis of Class07: \n",
      "size: 10821x400 -- maxValue: 1.70564969417 -- minValue: -0.199999701918\n",
      "analysis of Class08: \n",
      "size: 5898x400 -- maxValue: 2.29338655988 -- minValue: -0.199999534352\n",
      "analysis of Class09: \n",
      "size: 14562x400 -- maxValue: 2.27570297485 -- minValue: -0.199999369207\n",
      "analysis of Class10: \n",
      "size: 23224x400 -- maxValue: 2.98432190517 -- minValue: -0.19999981523\n",
      "analysis of Class11: \n",
      "size: 5633x400 -- maxValue: 1.41983426296 -- minValue: -0.199998880227\n",
      "analysis of Class12: \n",
      "size: 3192x400 -- maxValue: 1.44330456156 -- minValue: -0.199999742541\n",
      "analysis of Class13: \n",
      "size: 11314x400 -- maxValue: 4.19032063272 -- minValue: -0.199999962494\n",
      "analysis of Class14: \n",
      "size: 5542x400 -- maxValue: 2.56827449157 -- minValue: -0.199999809997\n",
      "analysis of Class15: \n",
      "size: 2582x400 -- maxValue: 1.57087579318 -- minValue: -0.19999950571\n",
      "analysis of Class16: \n",
      "size: 19233x400 -- maxValue: 2.4677985999 -- minValue: -0.199999971812\n",
      "analysis of Class17: \n",
      "size: 5428x400 -- maxValue: 1.79422297336 -- minValue: -0.199999481368\n",
      "analysis of Class18: \n",
      "size: 3614x400 -- maxValue: 1.20243252671 -- minValue: -0.199997079571\n",
      "analysis of Class19: \n",
      "size: 5493x400 -- maxValue: 2.27280567659 -- minValue: -0.199999870922\n",
      "analysis of Class20: \n",
      "size: 3031x400 -- maxValue: 1.03390659642 -- minValue: -0.199997067053\n",
      "analysis of Class21: \n",
      "size: 5292x400 -- maxValue: 2.00508879586 -- minValue: -0.199999952879\n",
      "analysis of Class22: \n",
      "size: 16225x400 -- maxValue: 2.77933588329 -- minValue: -0.199999730513\n",
      "analysis of Class23: \n",
      "size: 45589x400 -- maxValue: 2.66151690508 -- minValue: -0.1999999395\n",
      "analysis of Class24: \n",
      "size: 13816x400 -- maxValue: 1.4982179153 -- minValue: -0.199999971246\n",
      "end of class analysis\n"
     ]
    }
   ],
   "source": [
    "#Function for Dataset\n",
    "from Functions.dataset.shipClasses import LoadData\n",
    "import numpy as np\n",
    "\n",
    "dt_24 = LoadData()\n",
    "dt_24.infoData()\n",
    "all_data,all_trgt= dt_24.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_interest = [1,2,9,10,13,14,16,21,22,23]\n",
    "\n",
    "dt_24.setRangeClass(map(lambda x:x-1,class_interest))\n",
    "#map(lambda x:x-1,class_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class01', 'Class02', 'Class09', 'Class10', 'Class13', 'Class14', 'Class16', 'Class21', 'Class22', 'Class23']\n",
      "['Class01' 'Class02' 'Class09' 'Class10' 'Class13' 'Class14' 'Class16'\n",
      " 'Class21' 'Class22' 'Class23']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venancio/sonarteste/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "print dt_24.class_labels\n",
    "le.fit(dt_24.class_labels)\n",
    "print le.classes_\n",
    "y_label = le.inverse_transform(map(int,dt_24.all_trgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venancio/sonarteste/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functions.dataset.shipClasses.LoadData at 0x1e47890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_classes = {'ClassA1':['Class{0:02d}'.format(i) for i in [9,10,13,14,16]],\n",
    "               'ClassA2':['Class{0:02d}'.format(i) for i in [1,2,22,23]],\n",
    "               'ClassA3':'Class21'}\n",
    "\n",
    "\n",
    "dt_24.mapClasses(map_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassA1', 'ClassA2', 'ClassA3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_24.class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis of ClassA1: \n",
      "size: 73875x400 -- maxValue: 4.19032063272 -- minValue: -0.199999971812\n",
      "analysis of ClassA2: \n",
      "size: 68060x400 -- maxValue: 2.77933588329 -- minValue: -0.1999999395\n",
      "analysis of ClassA3: \n",
      "size: 5292x400 -- maxValue: 2.00508879586 -- minValue: -0.199999952879\n",
      "end of class analysis\n"
     ]
    }
   ],
   "source": [
    "dt_24.infoData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73875\n",
      "68060\n",
      "5292\n"
     ]
    }
   ],
   "source": [
    "teste = [len(dt_24.all_trgt[dt_24.all_trgt==i]) for i in range(3)]\n",
    "for i in teste:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.preprocessing import CVClassifier\n",
    "\n",
    "cvo = CVClassifier(,dt_24.all_data,dt_24.all_trgt,n_folds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Time to read data file: 2.91407179832 seconds\n"
     ]
    }
   ],
   "source": [
    "#DataModule\n",
    "\n",
    "analysis = nna(analysis_name=\"NeuralNetwork\",development_flag=True,development_events=400,verbose=False)\n",
    "#analysis.infoData()\n",
    "#analysis.setRangeClass([i-1 for i in class_interest])\n",
    "#analysis.balanceData()\n",
    "#analysis.infoData()\n",
    "weight_class = analysis.getClassesWeight(flag=True)\n",
    "all_data,all_trgt,_ = analysis.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train: 176130\n",
      "shape of X_test: 44033\n",
      "shape of y_train: 176130\n",
      "shape of y_test: 44033\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from hep_ml.nnet import MLPClassifier\n",
    "#from hep_ml.nnet import MLPMultiClassifier\n",
    "from Functions.MLPClassification import MLPSKlearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier,VotingClassifier\n",
    "\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(40,),\n",
    "#                    activation='tanh',\n",
    "#                    solver='adam',\n",
    "#                    alpha=0.0001, \n",
    "#                    batch_size='auto',\n",
    "#                    learning_rate='constant',\n",
    "#                    learning_rate_init=0.001,\n",
    "#                    power_t=0.5,\n",
    "#                    max_iter=1000,\n",
    "#                    shuffle=True,\n",
    "#                    random_state=None,\n",
    "#                    tol=0.01,\n",
    "#                    verbose=True,\n",
    "#                    warm_start=False,\n",
    "#                    momentum=0.9,\n",
    "#                    nesterovs_momentum=True,\n",
    "#                    early_stopping=True,\n",
    "#                    validation_fraction=0.2,\n",
    "#                    beta_1=0.9,\n",
    "#                    beta_2=0.999,\n",
    "#                    epsilon=1e-08)\n",
    "\n",
    "#neural = MLPClassifier(layers=[10], trainer='adadelta', trainer_parameters={'batch': 600})\n",
    "#mlp = MLPMultiClassifier(layers=(10,), scaler='standard', trainer='irprop-', epochs=100,\n",
    "#                 trainer_parameters=None, random_state=None)\n",
    "\n",
    "mlp = MLPSKlearn()\n",
    "\n",
    "\n",
    "estimator = 5\n",
    "classifier = AdaBoostClassifier(base_estimator=mlp, n_estimators=estimator)\n",
    "#mlp = MLPClassifier()\n",
    "#mj_vot = VotingClassifier(tuple(classifier.estimators_),n_jobs=-1)\n",
    "#preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_trgt, test_size=0.2)\n",
    "\n",
    "print 'shape of X_train: %d'%X_train.shape[0]\n",
    "print 'shape of X_test: %d'%X_test.shape[0]\n",
    "print 'shape of y_train: %d'%y_train.shape[0]\n",
    "print 'shape of y_test: %d'%y_test.shape[0]\n",
    "\n",
    "scale = StandardScaler().fit(X_train)\n",
    "data_preproc_train = scale.transform(X_train)\n",
    "data_preproc_test = scale.transform(X_test)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "trgt_preproc =ohe.fit_transform(pd.DataFrame(y_train,columns=['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] 1 of 1 inits\n",
      "Epoch 1/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 2.2882e-07 - acc: 0.0809\n",
      "Epoch 2/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 2.0793e-07 - acc: 0.2370\n",
      "Epoch 3/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.8676e-07 - acc: 0.3528\n",
      "Epoch 4/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.7380e-07 - acc: 0.4075\n",
      "Epoch 5/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.6518e-07 - acc: 0.4424\n",
      "Epoch 6/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.5845e-07 - acc: 0.4718\n",
      "Epoch 7/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.5264e-07 - acc: 0.4988\n",
      "Epoch 8/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.4774e-07 - acc: 0.5188\n",
      "Epoch 9/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.4359e-07 - acc: 0.5356\n",
      "Epoch 10/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3992e-07 - acc: 0.5513\n",
      "Epoch 11/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3653e-07 - acc: 0.5641\n",
      "Epoch 12/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3338e-07 - acc: 0.5771\n",
      "Epoch 13/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3050e-07 - acc: 0.5884\n",
      "Epoch 14/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2785e-07 - acc: 0.5981\n",
      "Epoch 15/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2546e-07 - acc: 0.6073\n",
      "Epoch 16/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2335e-07 - acc: 0.6144\n",
      "Epoch 17/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2146e-07 - acc: 0.6208\n",
      "Epoch 18/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1976e-07 - acc: 0.6267\n",
      "Epoch 19/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1820e-07 - acc: 0.6319\n",
      "Epoch 20/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1675e-07 - acc: 0.6369\n",
      "[+] 1 of 1 inits\n",
      "Epoch 1/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 2.2741e-07 - acc: 0.0347\n",
      "Epoch 2/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 2.0267e-07 - acc: 0.0428\n",
      "Epoch 3/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.7119e-07 - acc: 0.0508\n",
      "Epoch 4/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.5443e-07 - acc: 0.0580\n",
      "Epoch 5/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.4525e-07 - acc: 0.0626\n",
      "Epoch 6/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3915e-07 - acc: 0.0679\n",
      "Epoch 7/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3418e-07 - acc: 0.0726\n",
      "Epoch 8/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.3037e-07 - acc: 0.0765\n",
      "Epoch 9/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2738e-07 - acc: 0.0798\n",
      "Epoch 10/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2477e-07 - acc: 0.0828\n",
      "Epoch 11/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2258e-07 - acc: 0.0857\n",
      "Epoch 12/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.2062e-07 - acc: 0.0878\n",
      "Epoch 13/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1892e-07 - acc: 0.0900\n",
      "Epoch 14/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1731e-07 - acc: 0.0920\n",
      "Epoch 15/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1596e-07 - acc: 0.0938\n",
      "Epoch 16/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1457e-07 - acc: 0.0957\n",
      "Epoch 17/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1341e-07 - acc: 0.0976\n",
      "Epoch 18/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1221e-07 - acc: 0.0992\n",
      "Epoch 19/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1106e-07 - acc: 0.1009\n",
      "Epoch 20/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.1000e-07 - acc: 0.1029\n",
      "[+] 1 of 1 inits\n",
      "Epoch 1/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.9705e-07 - acc: 0.0766\n",
      "Epoch 2/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 1.0342e-07 - acc: 0.1190\n",
      "Epoch 3/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 8.9063e-08 - acc: 0.1256\n",
      "Epoch 4/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 8.4652e-08 - acc: 0.1303\n",
      "Epoch 5/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 8.1695e-08 - acc: 0.1356\n",
      "Epoch 6/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.9211e-08 - acc: 0.1412\n",
      "Epoch 7/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.7061e-08 - acc: 0.1487\n",
      "Epoch 8/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.5194e-08 - acc: 0.1560\n",
      "Epoch 9/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.3495e-08 - acc: 0.1635\n",
      "Epoch 10/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.1890e-08 - acc: 0.1727\n",
      "Epoch 11/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 7.0487e-08 - acc: 0.1812\n",
      "Epoch 12/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.9217e-08 - acc: 0.1892\n",
      "Epoch 13/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.8080e-08 - acc: 0.1964\n",
      "Epoch 14/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.7050e-08 - acc: 0.2028\n",
      "Epoch 15/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.6125e-08 - acc: 0.2080\n",
      "Epoch 16/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.5277e-08 - acc: 0.2130\n",
      "Epoch 17/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.4517e-08 - acc: 0.2170\n",
      "Epoch 18/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.3803e-08 - acc: 0.2205\n",
      "Epoch 19/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.3146e-08 - acc: 0.2238\n",
      "Epoch 20/20\n",
      "176130/176130 [==============================] - 3s 16us/step - loss: 6.2537e-08 - acc: 0.2265\n",
      "[+] 1 of 1 inits\n",
      "Epoch 1/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 2.0762e-07 - acc: 0.0397\n",
      "Epoch 2/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.4781e-07 - acc: 0.0419\n",
      "Epoch 3/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.1975e-07 - acc: 0.0461\n",
      "Epoch 4/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.1022e-07 - acc: 0.0500\n",
      "Epoch 5/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.0465e-07 - acc: 0.0558\n",
      "Epoch 6/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.0013e-07 - acc: 0.0632\n",
      "Epoch 7/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 9.6552e-08 - acc: 0.0698\n",
      "Epoch 8/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 9.3303e-08 - acc: 0.0778\n",
      "Epoch 9/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 9.0531e-08 - acc: 0.0835\n",
      "Epoch 10/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 8.8633e-08 - acc: 0.0894\n",
      "Epoch 11/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 8.6608e-08 - acc: 0.0946\n",
      "Epoch 12/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 8.4911e-08 - acc: 0.0989\n",
      "Epoch 13/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 8.3121e-08 - acc: 0.1038\n",
      "Epoch 14/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 8.1452e-08 - acc: 0.1082\n",
      "Epoch 15/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.9890e-08 - acc: 0.1125\n",
      "Epoch 16/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.8865e-08 - acc: 0.1162\n",
      "Epoch 17/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.7674e-08 - acc: 0.1198\n",
      "Epoch 18/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.6463e-08 - acc: 0.1239\n",
      "Epoch 19/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.5732e-08 - acc: 0.1274\n",
      "Epoch 20/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.4567e-08 - acc: 0.1310\n",
      "[+] 1 of 1 inits\n",
      "Epoch 1/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 1.7487e-07 - acc: 0.0757\n",
      "Epoch 2/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 9.1304e-08 - acc: 0.1077\n",
      "Epoch 3/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.9858e-08 - acc: 0.1125\n",
      "Epoch 4/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.5234e-08 - acc: 0.1141\n",
      "Epoch 5/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.2617e-08 - acc: 0.1159\n",
      "Epoch 6/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 7.0829e-08 - acc: 0.1176\n",
      "Epoch 7/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.9368e-08 - acc: 0.1208\n",
      "Epoch 8/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.7976e-08 - acc: 0.1246\n",
      "Epoch 9/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.6610e-08 - acc: 0.1291\n",
      "Epoch 10/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.5302e-08 - acc: 0.1341\n",
      "Epoch 11/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.4186e-08 - acc: 0.1384\n",
      "Epoch 12/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.3219e-08 - acc: 0.1426\n",
      "Epoch 13/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.2292e-08 - acc: 0.1466\n",
      "Epoch 14/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.1423e-08 - acc: 0.1510\n",
      "Epoch 15/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 6.0620e-08 - acc: 0.1547\n",
      "Epoch 16/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 5.9862e-08 - acc: 0.1592\n",
      "Epoch 17/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 5.9139e-08 - acc: 0.1631\n",
      "Epoch 18/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 5.8458e-08 - acc: 0.1674\n",
      "Epoch 19/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 5.7798e-08 - acc: 0.1708\n",
      "Epoch 20/20\n",
      "176130/176130 [==============================] - 3s 17us/step - loss: 5.7159e-08 - acc: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=MLPSKlearn(activation=None, alpha=None, batch_size=None, beta_1=None,\n",
       "      beta_2=None, dir=None, early_stopping=None, epsilon=None,\n",
       "      hidden_layer_sizes=None, learning_rate=None, learning_rate_init=None,\n",
       "      max_iter=None, momentum=None, n_iter_no_change=None,\n",
       "      nesterovs_momentum=None, power_t=None, shuffle=None, solver=None,\n",
       "      tol=None, validation_fraction=None, verbose=None, warm_start=None),\n",
       "          learning_rate=1.0, n_estimators=5, random_state=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usingo only MLP simple \n",
    "#mlp.fit(data_preproc_train,y_train)\n",
    "\n",
    "#using MLP with boosting\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "#mj_vot = VotingClassifier(zip(['est{0}'.format(i) for i in range(estimator)],\n",
    "#                              classifier.estimators_),\n",
    "#                          n_jobs=-1)\n",
    "#using votMaj with boosting MLP\n",
    "#mj_vot.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in classifier.estimators_:\n",
    "    print est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         9\n",
      "          1       1.00      0.67      0.80         9\n",
      "          2       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.92      0.90      0.90        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venancio/sonarteste/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "output_classes = mj_vot.predict(X=X_test)\n",
    "print classification_report(y_pred=output_classes,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.22044605e-16 3.21770927e-02 9.67822907e-01]\n",
      " [2.22044605e-16 9.99843719e-01 1.56280545e-04]\n",
      " [2.22044605e-16 9.99964050e-01 3.59500227e-05]\n",
      " [2.22044605e-16 3.71907841e-05 9.99962809e-01]\n",
      " [2.22044605e-16 1.06661147e-03 9.98933389e-01]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 2.71301116e-04 9.99728699e-01]\n",
      " [2.22044605e-16 4.02871556e-05 9.99959713e-01]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 1.94059398e-01 8.05940602e-01]\n",
      " [2.22044605e-16 9.99922729e-01 7.72705063e-05]\n",
      " [2.22044605e-16 1.40534761e-05 9.99985947e-01]\n",
      " [2.22044605e-16 2.20618720e-02 9.77938128e-01]\n",
      " [2.22044605e-16 9.99236248e-01 7.63752128e-04]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 9.99221564e-01 7.78435675e-04]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 2.78683062e-04 9.99721317e-01]\n",
      " [2.22044605e-16 1.35665469e-06 9.99998643e-01]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 9.91388735e-01 8.61126490e-03]\n",
      " [2.22044605e-16 9.99933764e-01 6.62358153e-05]\n",
      " [1.00000000e+00 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 9.99997960e-01 2.03953446e-06]\n",
      " [2.22044605e-16 2.83593229e-01 7.16406771e-01]\n",
      " [2.22044605e-16 9.99990959e-01 9.04068101e-06]]\n"
     ]
    }
   ],
   "source": [
    "for each_mlp in classifier.staged_predict_proba(X_test):\n",
    "    print each_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "BaggingClassifier\n",
      "BernoulliNB\n",
      "CalibratedClassifierCV\n",
      "DecisionTreeClassifier\n",
      "ExtraTreeClassifier\n",
      "ExtraTreesClassifier\n",
      "GaussianNB\n",
      "GradientBoostingClassifier\n",
      "LinearSVC\n",
      "LogisticRegression\n",
      "LogisticRegressionCV\n",
      "MultinomialNB\n",
      "NuSVC\n",
      "Perceptron\n",
      "RandomForestClassifier\n",
      "RidgeClassifier\n",
      "RidgeClassifierCV\n",
      "SGDClassifier\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from sklearn.utils.testing import all_estimators\n",
    "for name, clf in all_estimators(type_filter='classifier'):\n",
    "    if 'sample_weight' in inspect.getargspec(clf().fit)[0]:\n",
    "        print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_sample_weight(self, sample_weight, n_samples):\n",
    "        \"\"\"Set the sample weight array.\"\"\"\n",
    "        if sample_weight is None:\n",
    "            # uniform sample weights\n",
    "            sample_weight = np.ones(n_samples, dtype=np.float64, order='C')\n",
    "        else:\n",
    "            # user-provided array\n",
    "            sample_weight = np.asarray(sample_weight, dtype=np.float64,\n",
    "                                       order=\"C\")\n",
    "        if sample_weight.shape[0] != n_samples:\n",
    "            raise ValueError(\"Shapes of X and sample_weight do not match.\")\n",
    "        return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 4\n"
     ]
    }
   ],
   "source": [
    "print n_samples,n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
